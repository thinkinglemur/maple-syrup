#!/usr/bin/env bash
# lib/generators/generate_init.sh
# Writes ./init.sh — the per-project bootstrap script

generate_init_sh() {
  local out="./init.sh"

  cat > "$out" <<'INIT_HEADER'
#!/usr/bin/env bash
set -euo pipefail

# ─────────────────────────────────────────────────────────────
#  init.sh  — generated by project-bootstrap
#  Run this once to fully scaffold your project.
#  Commit this file back to your repo.
# ─────────────────────────────────────────────────────────────

RED='\033[0;31m'; GREEN='\033[0;32m'; YELLOW='\033[1;33m'
CYAN='\033[0;36m'; BOLD='\033[1m'; DIM='\033[2m'; NC='\033[0m'

step()  { echo -e "\n${BOLD}${CYAN}▶ $1${NC}"; }
ok()    { echo -e "  ${GREEN}✔ $1${NC}"; }
info()  { echo -e "  ${DIM}$1${NC}"; }
warn()  { echo -e "  ${YELLOW}⚠ $1${NC}"; }

INIT_HEADER

  # ── Embed the chosen config as variables ────────────────────
  cat >> "$out" <<VARS
# ── Project config (generated by setup.sh) ───────────────────
PROJECT_NAME="${PROJECT_NAME}"
LANGUAGE="${CHOSEN_LANGUAGE}"
FRAMEWORK="${CHOSEN_FRAMEWORK}"
DATABASE="${CHOSEN_DATABASE}"
CACHE="${CHOSEN_CACHE}"
DEPLOY_TARGET="${CHOSEN_DEPLOY}"
SYNOPSIS="${PROJECT_SYNOPSIS//\"/\\\"}"

VARS

  # ── Create directory structure ──────────────────────────────
  cat >> "$out" <<'DIRS'

step "Creating project structure..."
mkdir -p src tests docs .github/workflows
ok "Directories created"

DIRS

  # ── Tool version checks ─────────────────────────────────────
  _append_tool_checks "$out"

  # ── Language-specific init ───────────────────────────────────
  _append_language_init "$out"

  # ── Dockerfile ──────────────────────────────────────────────
  _append_dockerfile "$out"

  # ── docker-compose.yml ──────────────────────────────────────
  _append_compose "$out"

  # ── .env.example ────────────────────────────────────────────
  _append_env_example "$out"

  # ── GitHub Actions workflows ─────────────────────────────────
  _append_github_actions "$out"

  # ── README.md ────────────────────────────────────────────────
  _append_readme "$out"

  # ── Final message ────────────────────────────────────────────
  cat >> "$out" <<'DONE'

echo ""
echo -e "${GREEN}╔══════════════════════════════════════════╗${NC}"
echo -e "${GREEN}║   ✅  Project scaffolded!                ║${NC}"
echo -e "${GREEN}╚══════════════════════════════════════════╝${NC}"
echo ""
echo "  Next steps:"
echo "  1. cp .env.example .env  →  fill in secrets"
echo "  2. docker compose up --build"
echo "  3. aider  (start coding!)"
echo ""
DONE

  chmod +x "$out"
  ok "init.sh generated → run ./init.sh to scaffold your project"
}

# ─────────────────────────────────────────────────────────────
#  Language-specific package init blocks
# ─────────────────────────────────────────────────────────────
_append_language_init() {
  local out="$1"

  case "$CHOSEN_LANGUAGE" in

    TypeScript)
      _append_typescript_init "$out"
      ;;

    Python)
      _append_python_init "$out"
      ;;

    Rust)
      _append_rust_init "$out"
      ;;

    Go)
      _append_go_init "$out"
      ;;

    PHP)
      _append_php_init "$out"
      ;;
  esac
}

# ─── TypeScript ──────────────────────────────────────────────
_append_typescript_init() {
  local out="$1"
  cat >> "$out" <<'TS_INIT'

step "Initialising TypeScript project..."

# Detect package manager + executor (npx / pnpm dlx / bunx)
PM="npm"
PMX="npx"
command -v pnpm &>/dev/null && PM="pnpm" && PMX="pnpm dlx"
command -v bun  &>/dev/null && PM="bun"  && PMX="bunx"
info "Using package manager: $PM"

# package.json
cat > package.json <<PKG
{
  "name": "$PROJECT_NAME",
  "version": "0.1.0",
  "private": true,
  "scripts": {
    "dev":   "next dev",
    "build": "next build",
    "start": "next start",
    "lint":  "eslint .",
    "test":  "vitest run"
  }
}
PKG
TS_INIT

  # Framework-specific install
  case "$CHOSEN_FRAMEWORK" in
    "Next.js")
      cat >> "$out" <<'NEXTJS'

# Bootstrap Next.js into a temp dir then merge back (avoids "directory contains files" error)
SCAFFOLD_TMP=$(mktemp -d)
$PMX create-next-app@latest "$SCAFFOLD_TMP/scaffold" \
  --typescript \
  --tailwind \
  --eslint \
  --app \
  --src-dir \
  --import-alias "@/*" \
  --no-git \
  --yes
# Merge scaffold into current directory (existing files like .gitignore are kept)
cp -rn "$SCAFFOLD_TMP/scaffold/." .
rm -rf "$SCAFFOLD_TMP"
ok "Next.js scaffolded"
NEXTJS
      ;;
    "Remix")
      cat >> "$out" <<'REMIX'

SCAFFOLD_TMP=$(mktemp -d)
$PMX create-remix@latest "$SCAFFOLD_TMP/scaffold" --template remix-run/remix/templates/remix --typescript --no-git
cp -rn "$SCAFFOLD_TMP/scaffold/." .
rm -rf "$SCAFFOLD_TMP"
ok "Remix scaffolded"
REMIX
      ;;
    "NestJS")
      cat >> "$out" <<'NESTJS'

SCAFFOLD_TMP=$(mktemp -d)
$PMX @nestjs/cli new "$SCAFFOLD_TMP/scaffold" --package-manager "${PM}" --skip-git --strict
cp -rn "$SCAFFOLD_TMP/scaffold/." .
rm -rf "$SCAFFOLD_TMP"
ok "NestJS scaffolded"
NESTJS
      ;;
    "Express"|"Fastify")
      cat >> "$out" <<'EXPRESS'

$PM init -y
$PM add typescript ts-node @types/node
$PM add -D tsx
npx tsc --init --target ES2022 --module commonjs --rootDir src --outDir dist --strict --esModuleInterop
mkdir -p src
ok "TypeScript project initialised"
EXPRESS
      ;;
  esac

  # Sentry + GA packages for TS
  cat >> "$out" <<'TS_EXTRAS'

step "Installing observability packages..."
$PM add @sentry/nextjs posthog-js
ok "Sentry + PostHog installed"

# Sentry config stub
cat > sentry.client.config.ts <<SENTRY
import * as Sentry from "@sentry/nextjs";

Sentry.init({
  dsn: process.env.NEXT_PUBLIC_SENTRY_DSN,
  tracesSampleRate: 1.0,
  environment: process.env.NODE_ENV,
});
SENTRY

cat > sentry.server.config.ts <<SENTRY
import * as Sentry from "@sentry/nextjs";

Sentry.init({
  dsn: process.env.NEXT_PUBLIC_SENTRY_DSN,
  tracesSampleRate: 1.0,
  environment: process.env.NODE_ENV,
});
SENTRY

# Analytics stub (src/lib/analytics.ts)
mkdir -p src/lib
cat > src/lib/analytics.ts <<ANALYTICS
// Google Analytics 4 helper
export const GA_MEASUREMENT_ID = process.env.NEXT_PUBLIC_GA_MEASUREMENT_ID ?? "";

export function pageview(url: string) {
  if (typeof window !== "undefined" && (window as any).gtag) {
    (window as any).gtag("config", GA_MEASUREMENT_ID, { page_path: url });
  }
}

export function event(action: string, params: Record<string, unknown> = {}) {
  if (typeof window !== "undefined" && (window as any).gtag) {
    (window as any).gtag("event", action, params);
  }
}
ANALYTICS

ok "Sentry + Analytics stubs written"
TS_EXTRAS
}

# ─── Python ───────────────────────────────────────────────────
_append_python_init() {
  local out="$1"

  local framework_pkg
  case "$CHOSEN_FRAMEWORK" in
    FastAPI) framework_pkg="fastapi[standard] uvicorn[standard]" ;;
    Django)  framework_pkg="django" ;;
    Flask)   framework_pkg="flask[async]" ;;
    *)       framework_pkg="fastapi[standard]" ;;
  esac

  cat >> "$out" <<PYINIT

step "Initialising Python project..."
python3 -m venv .venv
source .venv/bin/activate
pip install --upgrade pip -q

pip install ${framework_pkg} sentry-sdk python-dotenv
ok "${CHOSEN_FRAMEWORK} installed"

# pyproject.toml
cat > pyproject.toml <<PYPROJECT
[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project]
name = "$PROJECT_NAME"
version = "0.1.0"
requires-python = ">=3.12"

[tool.ruff]
line-length = 88
select = ["E", "F", "I"]

[tool.mypy]
strict = true
PYPROJECT

PYINIT

  case "$CHOSEN_FRAMEWORK" in
    FastAPI)
      cat >> "$out" <<'FASTAPI'
# FastAPI main app
cat > src/main.py <<APP
import sentry_sdk
from fastapi import FastAPI
from contextlib import asynccontextmanager
from dotenv import load_dotenv
import os

load_dotenv()

sentry_sdk.init(
    dsn=os.getenv("SENTRY_DSN", ""),
    traces_sample_rate=1.0,
    environment=os.getenv("ENVIRONMENT", "development"),
)

@asynccontextmanager
async def lifespan(app: FastAPI):
    # startup
    yield
    # shutdown

app = FastAPI(title="$PROJECT_NAME", lifespan=lifespan)

@app.get("/health")
async def health():
    return {"status": "ok"}
APP
ok "FastAPI app created → src/main.py"
FASTAPI
      ;;
    Django)
      cat >> "$out" <<'DJANGO'
django-admin startproject config .
python manage.py startapp core src/
ok "Django project created"
DJANGO
      ;;
    Flask)
      cat >> "$out" <<'FLASK'
cat > src/app.py <<APP
import sentry_sdk
from flask import Flask
from dotenv import load_dotenv
import os

load_dotenv()

sentry_sdk.init(
    dsn=os.getenv("SENTRY_DSN", ""),
    traces_sample_rate=1.0,
)

app = Flask(__name__)

@app.get("/health")
def health():
    return {"status": "ok"}

if __name__ == "__main__":
    app.run(debug=True)
APP
ok "Flask app created → src/app.py"
FLASK
      ;;
  esac
}

# ─── Rust ─────────────────────────────────────────────────────
_append_rust_init() {
  local out="$1"
  cat >> "$out" <<'RUSTINIT'

step "Initialising Rust project..."
cargo init --name "$PROJECT_NAME" .

case "$FRAMEWORK" in
  Axum)
    cat >> Cargo.toml <<TOML

[dependencies]
axum = "0.7"
tokio = { version = "1", features = ["full"] }
tower = "0.4"
tower-http = { version = "0.5", features = ["cors", "trace"] }
serde = { version = "1", features = ["derive"] }
serde_json = "1"
dotenvy = "0.15"
sentry = "0.34"
tracing = "0.1"
tracing-subscriber = { version = "0.3", features = ["env-filter"] }
TOML
    cat > src/main.rs <<'MAINRS'
use axum::{routing::get, Router};
use std::net::SocketAddr;

#[tokio::main]
async fn main() {
    dotenvy::dotenv().ok();
    tracing_subscriber::fmt::init();

    let _guard = sentry::init((
        std::env::var("SENTRY_DSN").unwrap_or_default(),
        sentry::ClientOptions {
            release: sentry::release_name!(),
            ..Default::default()
        },
    ));

    let app = Router::new()
        .route("/health", get(|| async { "ok" }));

    let addr = SocketAddr::from(([0, 0, 0, 0], 8080));
    tracing::info!("listening on {}", addr);
    let listener = tokio::net::TcpListener::bind(addr).await.unwrap();
    axum::serve(listener, app).await.unwrap();
}
MAINRS
    ;;
  Actix-web)
    cat >> Cargo.toml <<TOML

[dependencies]
actix-web = "4"
sentry = "0.34"
sentry-actix = "0.34"
dotenvy = "0.15"
tokio = { version = "1", features = ["full"] }
TOML
    ;;
esac

ok "Rust / $FRAMEWORK project initialised"
RUSTINIT
}

# ─── Go ───────────────────────────────────────────────────────
_append_go_init() {
  local out="$1"
  cat >> "$out" <<'GOINIT'

step "Initialising Go project..."
go mod init "github.com/your-org/$PROJECT_NAME"

case "$FRAMEWORK" in
  Gin)
    go get github.com/gin-gonic/gin
    go get github.com/getsentry/sentry-go
    cat > src/main.go <<'MAINGO'
package main

import (
	"net/http"
	"os"

	"github.com/getsentry/sentry-go"
	"github.com/gin-gonic/gin"
)

func main() {
	_ = sentry.Init(sentry.ClientOptions{
		Dsn:              os.Getenv("SENTRY_DSN"),
		TracesSampleRate: 1.0,
	})

	r := gin.Default()
	r.GET("/health", func(c *gin.Context) {
		c.JSON(http.StatusOK, gin.H{"status": "ok"})
	})
	r.Run(":8080")
}
MAINGO
    ;;
  Echo)
    go get github.com/labstack/echo/v4
    ;;
  Fiber)
    go get github.com/gofiber/fiber/v2
    ;;
esac

ok "Go / $FRAMEWORK project initialised"
GOINIT
}

# ─── PHP ──────────────────────────────────────────────────────
_append_php_init() {
  local out="$1"
  cat >> "$out" <<'PHPINIT'

step "Initialising PHP project..."

case "$FRAMEWORK" in
  Laravel)
    composer create-project laravel/laravel . --prefer-dist
    composer require sentry/sentry-laravel
    php artisan sentry:publish --dsn="${SENTRY_DSN:-}"
    ;;
  Symfony)
    composer create-project symfony/skeleton .
    composer require sentry/sentry-symfony
    ;;
esac

ok "PHP / $FRAMEWORK project initialised"
PHPINIT
}

# ─────────────────────────────────────────────────────────────
#  Dockerfile (multi-stage)
# ─────────────────────────────────────────────────────────────
_append_dockerfile() {
  local out="$1"

  cat >> "$out" <<'DFHEADER'

step "Writing Dockerfile..."
cat > Dockerfile <<'DOCKERFILE_CONTENT'
DFHEADER

  case "$CHOSEN_LANGUAGE" in
    TypeScript)
      cat >> "$out" <<'DNODE'
# ── Stage 1: deps ──────────────────────────────────────────────
FROM node:22-alpine AS deps
RUN apk add --no-cache libc6-compat
WORKDIR /app
COPY package*.json ./
RUN npm ci --frozen-lockfile

# ── Stage 2: builder ───────────────────────────────────────────
FROM node:22-alpine AS builder
WORKDIR /app
COPY --from=deps /app/node_modules ./node_modules
COPY . .
RUN npm run build

# ── Stage 3: runner ────────────────────────────────────────────
FROM node:22-alpine AS runner
WORKDIR /app
ENV NODE_ENV=production
RUN addgroup --system --gid 1001 nodejs
RUN adduser  --system --uid 1001 nextjs
COPY --from=builder --chown=nextjs:nodejs /app/.next/standalone ./
COPY --from=builder --chown=nextjs:nodejs /app/.next/static ./.next/static
USER nextjs
EXPOSE 3000
ENV PORT=3000
CMD ["node", "server.js"]
DNODE
      ;;
    Python)
      cat >> "$out" <<'DPYTHON'
# ── Stage 1: builder ───────────────────────────────────────────
FROM python:3.12-slim AS builder
WORKDIR /app
ENV PYTHONDONTWRITEBYTECODE=1 PYTHONUNBUFFERED=1
RUN pip install --upgrade pip
COPY requirements*.txt ./
RUN pip wheel --no-cache-dir --no-deps --wheel-dir /app/wheels -r requirements.txt

# ── Stage 2: runner ────────────────────────────────────────────
FROM python:3.12-slim AS runner
WORKDIR /app
ENV PYTHONDONTWRITEBYTECODE=1 PYTHONUNBUFFERED=1
COPY --from=builder /app/wheels /wheels
RUN pip install --no-cache /wheels/*
COPY . .
RUN addgroup --system app && adduser --system --group app
USER app
EXPOSE 8080
CMD ["uvicorn", "src.main:app", "--host", "0.0.0.0", "--port", "8080"]
DPYTHON
      ;;
    Rust)
      cat >> "$out" <<'DRUST'
# ── Stage 1: builder ───────────────────────────────────────────
FROM rust:1.77-alpine AS builder
RUN apk add --no-cache musl-dev
WORKDIR /app
COPY Cargo.toml Cargo.lock ./
# Cache deps
RUN mkdir src && echo "fn main() {}" > src/main.rs && cargo build --release
RUN rm -rf src
COPY src ./src
RUN touch src/main.rs && cargo build --release

# ── Stage 2: runner ────────────────────────────────────────────
FROM scratch AS runner
COPY --from=builder /app/target/release/app /app
EXPOSE 8080
CMD ["/app"]
DRUST
      ;;
    Go)
      cat >> "$out" <<'DGO'
# ── Stage 1: builder ───────────────────────────────────────────
FROM golang:1.22-alpine AS builder
RUN apk add --no-cache git
WORKDIR /app
COPY go.mod go.sum ./
RUN go mod download
COPY . .
RUN CGO_ENABLED=0 GOOS=linux go build -ldflags="-w -s" -o bin/server ./src/...

# ── Stage 2: runner ────────────────────────────────────────────
FROM scratch AS runner
COPY --from=builder /etc/ssl/certs/ca-certificates.crt /etc/ssl/certs/
COPY --from=builder /app/bin/server /server
EXPOSE 8080
CMD ["/server"]
DGO
      ;;
    PHP)
      cat >> "$out" <<'DPHP'
# ── Stage 1: composer ──────────────────────────────────────────
FROM composer:2 AS composer
WORKDIR /app
COPY composer.json composer.lock ./
RUN composer install --no-dev --prefer-dist --optimize-autoloader --no-scripts

# ── Stage 2: runner ────────────────────────────────────────────
FROM php:8.3-fpm-alpine AS runner
RUN apk add --no-cache nginx supervisor
WORKDIR /var/www/html
COPY . .
COPY --from=composer /app/vendor ./vendor
RUN php artisan config:cache && php artisan route:cache
EXPOSE 80
CMD ["php-fpm"]
DPHP
      ;;
  esac

  cat >> "$out" <<'DFCLOSE'
DOCKERFILE_CONTENT
ok "Dockerfile written (multi-stage)"
DFCLOSE
}

# ─────────────────────────────────────────────────────────────
#  docker-compose.yml
# ─────────────────────────────────────────────────────────────
_append_compose() {
  local out="$1"

  # Determine app port
  local app_port
  case "$CHOSEN_LANGUAGE" in
    TypeScript) app_port=3000 ;;
    PHP)        app_port=80   ;;
    *)          app_port=8080 ;;
  esac

  cat >> "$out" <<COMPOSE_HEADER

step "Writing docker-compose.yml..."
cat > docker-compose.yml <<'COMPOSE_CONTENT'
version: "3.9"

services:
  app:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "${APP_PORT:-${app_port}}:${app_port}"
    env_file:
      - .env
    depends_on:
COMPOSE_HEADER

  # DB service
  if [[ -n "$CHOSEN_DATABASE" ]]; then
    cat >> "$out" <<COMPOSE_DB
      - db
  db:
COMPOSE_DB
    case "$CHOSEN_DATABASE" in
      PostgreSQL)
        cat >> "$out" <<'PGDB'
    image: postgres:16-alpine
    environment:
      POSTGRES_USER:     ${DB_USER:-app}
      POSTGRES_PASSWORD: ${DB_PASSWORD:-secret}
      POSTGRES_DB:       ${DB_NAME:-appdb}
    volumes:
      - db_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
PGDB
        ;;
      MySQL)
        cat >> "$out" <<'MYDB'
    image: mysql:8.3
    environment:
      MYSQL_ROOT_PASSWORD: ${DB_ROOT_PASSWORD:-rootsecret}
      MYSQL_DATABASE:      ${DB_NAME:-appdb}
      MYSQL_USER:          ${DB_USER:-app}
      MYSQL_PASSWORD:      ${DB_PASSWORD:-secret}
    volumes:
      - db_data:/var/lib/mysql
    ports:
      - "3306:3306"
MYDB
        ;;
      MongoDB)
        cat >> "$out" <<'MONGO'
    image: mongo:7
    environment:
      MONGO_INITDB_ROOT_USERNAME: ${DB_USER:-app}
      MONGO_INITDB_ROOT_PASSWORD: ${DB_PASSWORD:-secret}
    volumes:
      - db_data:/data/db
    ports:
      - "27017:27017"
MONGO
        ;;
    esac
  fi

  # Cache service
  if [[ -n "$CHOSEN_CACHE" ]]; then
    case "$CHOSEN_CACHE" in
      Redis)
        cat >> "$out" <<'REDIS'
  cache:
    image: redis:7-alpine
    command: redis-server --save 60 1 --loglevel warning
    volumes:
      - cache_data:/data
    ports:
      - "6379:6379"
REDIS
        ;;
      Memcached)
        cat >> "$out" <<'MEMCACHED'
  cache:
    image: memcached:1.6-alpine
    ports:
      - "11211:11211"
MEMCACHED
        ;;
    esac
  fi

  # Volumes
  cat >> "$out" <<'VOLUMES'

volumes:
  db_data:
  cache_data:
COMPOSE_CONTENT
ok "docker-compose.yml written"
VOLUMES
}

# ─────────────────────────────────────────────────────────────
#  .env.example
# ─────────────────────────────────────────────────────────────
_append_env_example() {
  local out="$1"

  cat >> "$out" <<'ENVEX'

step "Writing .env.example..."
cat > .env.example <<'ENV_CONTENT'
# ── App ───────────────────────────────────────
APP_ENV=development
APP_PORT=3000
APP_SECRET=change-me-in-production

# ── Database ──────────────────────────────────
DB_HOST=db
DB_PORT=5432
DB_NAME=appdb
DB_USER=app
DB_PASSWORD=secret
DATABASE_URL=postgresql://${DB_USER}:${DB_PASSWORD}@${DB_HOST}:${DB_PORT}/${DB_NAME}

# ── Cache ─────────────────────────────────────
REDIS_URL=redis://cache:6379

# ── Observability ─────────────────────────────
SENTRY_DSN=
NEXT_PUBLIC_SENTRY_DSN=

# ── Analytics ─────────────────────────────────
NEXT_PUBLIC_GA_MEASUREMENT_ID=G-XXXXXXXXXX

# ── AWS (for deployment) ──────────────────────
AWS_REGION=us-east-1
AWS_ACCOUNT_ID=
ECR_REPOSITORY=
ECS_CLUSTER=
ECS_SERVICE=
ENV_CONTENT

ok ".env.example written"
ENVEX
}

# ─────────────────────────────────────────────────────────────
#  GitHub Actions workflows
# ─────────────────────────────────────────────────────────────
_append_github_actions() {
  local out="$1"

  cat >> "$out" <<'GHACTIONS'

step "Writing GitHub Actions workflows..."
mkdir -p .github/workflows

# ── CI: test + lint ─────────────────────────────────────────
GHACTIONS

  case "$CHOSEN_LANGUAGE" in
    TypeScript)
      cat >> "$out" <<'GHA_TS_CI'
cat > .github/workflows/ci.yml <<'WORKFLOW'
name: CI

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]

jobs:
  lint-and-test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-node@v4
        with:
          node-version: 22
          cache: npm

      - run: npm ci

      - name: Lint
        run: npm run lint

      - name: Type check
        run: npx tsc --noEmit

      - name: Test
        run: npm run test --if-present
WORKFLOW
GHA_TS_CI
      ;;
    Python)
      cat >> "$out" <<'GHA_PY_CI'
cat > .github/workflows/ci.yml <<'WORKFLOW'
name: CI

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]

jobs:
  lint-and-test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: "3.12"
          cache: pip

      - run: pip install ruff mypy pytest

      - name: Lint
        run: ruff check .

      - name: Type check
        run: mypy src

      - name: Test
        run: pytest tests/ -v --tb=short
WORKFLOW
GHA_PY_CI
      ;;
    Rust)
      cat >> "$out" <<'GHA_RS_CI'
cat > .github/workflows/ci.yml <<'WORKFLOW'
name: CI

on:
  push:
    branches: [main, develop]
  pull_request:

jobs:
  lint-and-test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: dtolnay/rust-toolchain@stable
        with:
          components: clippy, rustfmt
      - uses: Swatinem/rust-cache@v2
      - run: cargo fmt --check
      - run: cargo clippy -- -D warnings
      - run: cargo test
WORKFLOW
GHA_RS_CI
      ;;
    Go)
      cat >> "$out" <<'GHA_GO_CI'
cat > .github/workflows/ci.yml <<'WORKFLOW'
name: CI

on:
  push:
    branches: [main, develop]
  pull_request:

jobs:
  lint-and-test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-go@v5
        with:
          go-version: "1.22"
          cache: true

      - name: Vet
        run: go vet ./...

      - name: Test
        run: go test ./... -v -race -coverprofile=coverage.out
WORKFLOW
GHA_GO_CI
      ;;
    PHP)
      cat >> "$out" <<'GHA_PHP_CI'
cat > .github/workflows/ci.yml <<'WORKFLOW'
name: CI

on:
  push:
    branches: [main, develop]
  pull_request:

jobs:
  lint-and-test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - uses: shivammathur/setup-php@v2
        with:
          php-version: "8.3"

      - run: composer install --prefer-dist --no-progress

      - name: Test
        run: php artisan test
WORKFLOW
GHA_PHP_CI
      ;;
  esac

  # ── Deploy workflow based on target ─────────────────────────
  case "$CHOSEN_DEPLOY" in
    "AWS ECS Fargate")
      _append_aws_deploy_workflow "$out"
      ;;
    "Vercel")
      _append_vercel_deploy_workflow "$out"
      ;;
    "Railway")
      _append_railway_deploy_workflow "$out"
      ;;
  esac

  cat >> "$out" <<'GHOK'
ok "GitHub Actions workflows written"
GHOK
}

_append_aws_deploy_workflow() {
  local out="$1"
  cat >> "$out" <<'AWS_DEPLOY'

cat > .github/workflows/deploy.yml <<'WORKFLOW'
name: Deploy → AWS ECS Fargate

on:
  push:
    branches: [main]

env:
  AWS_REGION:       ${{ vars.AWS_REGION }}
  ECR_REPOSITORY:   ${{ vars.ECR_REPOSITORY }}
  ECS_CLUSTER:      ${{ vars.ECS_CLUSTER }}
  ECS_SERVICE:      ${{ vars.ECS_SERVICE }}
  CONTAINER_NAME:   app

jobs:
  deploy:
    name: Build & Deploy
    runs-on: ubuntu-latest
    permissions:
      id-token: write   # OIDC
      contents: read

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Configure AWS credentials (OIDC)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region:     ${{ env.AWS_REGION }}

      - name: Log in to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2

      - name: Build, tag & push image
        id: build-image
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          IMAGE_TAG:    ${{ github.sha }}
        run: |
          docker build -t $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG .
          docker push     $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG
          echo "image=$ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG" >> $GITHUB_OUTPUT

      - name: Download ECS task definition
        run: |
          aws ecs describe-task-definition \
            --task-definition $ECS_SERVICE \
            --query taskDefinition \
            > task-definition.json

      - name: Update container image in task def
        id: task-def
        uses: aws-actions/amazon-ecs-render-task-definition@v1
        with:
          task-definition: task-definition.json
          container-name:  ${{ env.CONTAINER_NAME }}
          image:           ${{ steps.build-image.outputs.image }}

      - name: Deploy to ECS
        uses: aws-actions/amazon-ecs-deploy-task-definition@v1
        with:
          task-definition:  ${{ steps.task-def.outputs.task-definition }}
          service:          ${{ env.ECS_SERVICE }}
          cluster:          ${{ env.ECS_CLUSTER }}
          wait-for-service-stability: true
WORKFLOW

# ── AWS infrastructure readme ────────────────────────────────
cat > docs/aws-setup.md <<'AWSDOC'
# AWS ECS Fargate Setup

## Prerequisites
- AWS CLI configured
- ECR repository created
- ECS cluster + service configured
- GitHub OIDC provider set up in IAM

## Required GitHub Secrets
| Secret | Description |
|--------|-------------|
| `AWS_ROLE_ARN` | IAM role ARN for OIDC (e.g. `arn:aws:iam::123:role/github-actions`) |

## Required GitHub Variables
| Variable | Description |
|----------|-------------|
| `AWS_REGION` | e.g. `us-east-1` |
| `ECR_REPOSITORY` | ECR repo name |
| `ECS_CLUSTER` | ECS cluster name |
| `ECS_SERVICE` | ECS service name |

## IAM Role Policy (minimum)
The OIDC role needs:
- `ecr:GetAuthorizationToken` + ECR push permissions
- `ecs:DescribeTaskDefinition` + `ecs:RegisterTaskDefinition`
- `ecs:UpdateService` + `ecs:DescribeServices`
- `iam:PassRole` for the ECS task execution role
AWSDOC
AWS_DEPLOY
}

_append_vercel_deploy_workflow() {
  local out="$1"
  cat >> "$out" <<'VERCEL_DEPLOY'

cat > .github/workflows/deploy.yml <<'WORKFLOW'
name: Deploy → Vercel

on:
  push:
    branches: [main]

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Deploy to Vercel
        uses: amondnet/vercel-action@v25
        with:
          vercel-token:   ${{ secrets.VERCEL_TOKEN }}
          vercel-org-id:  ${{ secrets.VERCEL_ORG_ID }}
          vercel-project-id: ${{ secrets.VERCEL_PROJECT_ID }}
          vercel-args:    --prod
WORKFLOW
VERCEL_DEPLOY
}

_append_railway_deploy_workflow() {
  local out="$1"
  cat >> "$out" <<'RAILWAY_DEPLOY'

cat > .github/workflows/deploy.yml <<'WORKFLOW'
name: Deploy → Railway

on:
  push:
    branches: [main]

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Install Railway CLI
        run: npm i -g @railway/cli

      - name: Deploy
        run: railway up --service ${{ vars.RAILWAY_SERVICE }} --detach
        env:
          RAILWAY_TOKEN: ${{ secrets.RAILWAY_TOKEN }}
WORKFLOW
RAILWAY_DEPLOY
}

# ─────────────────────────────────────────────────────────────
#  README.md
# ─────────────────────────────────────────────────────────────
_append_readme() {
  local out="$1"

  cat >> "$out" <<'README_START'

step "Writing README.md..."
cat > README.md <<READMEEOF
# $PROJECT_NAME

> $SYNOPSIS

## Stack

| Layer     | Choice             |
|-----------|--------------------|
| Language  | $LANGUAGE          |
| Framework | $FRAMEWORK         |
| Database  | ${DATABASE:-—}     |
| Cache     | ${CACHE:-—}        |
| Deploy    | $DEPLOY_TARGET     |

## Getting started

### Prerequisites
- [Docker](https://docs.docker.com/get-docker/) + Docker Compose
- [git](https://git-scm.com/)

### Local development

\`\`\`bash
# 1. Clone
git clone <your-repo-url> && cd $PROJECT_NAME

# 2. Configure environment
cp .env.example .env
# Edit .env with your values

# 3. Start services
docker compose up --build

# 4. Visit
open http://localhost:3000
\`\`\`

## Project structure

\`\`\`
.
├── src/                  # Application source
├── tests/                # Test files
├── docs/                 # Documentation
├── .github/workflows/    # CI/CD pipelines
├── Dockerfile            # Multi-stage Docker build
├── docker-compose.yml    # Local services
├── .env.example          # Environment variable template
├── .aider.conf.yml       # Aider AI config
└── README.md
\`\`\`

## Development workflow

\`\`\`bash
# Run with hot reload (framework-specific)
docker compose up

# Run tests
docker compose run --rm app <test-command>

# AI-assisted coding
aider
\`\`\`

## Deployment

This project deploys to **$DEPLOY_TARGET** via GitHub Actions.

See [\`.github/workflows/deploy.yml\`](.github/workflows/deploy.yml) for the pipeline.
$([ "$DEPLOY_TARGET" = "AWS ECS Fargate" ] && echo "See [\`docs/aws-setup.md\`](docs/aws-setup.md) for AWS setup instructions.")

### Required secrets

Set these in your GitHub repository settings → Secrets and variables:

$(
case "$DEPLOY_TARGET" in
  "AWS ECS Fargate")
    echo "- \`AWS_ROLE_ARN\` — IAM OIDC role for GitHub Actions"
    echo "- \`AWS_REGION\`, \`ECR_REPOSITORY\`, \`ECS_CLUSTER\`, \`ECS_SERVICE\` (as Variables)"
    ;;
  "Vercel")
    echo "- \`VERCEL_TOKEN\`"
    echo "- \`VERCEL_ORG_ID\`"
    echo "- \`VERCEL_PROJECT_ID\`"
    ;;
  "Railway")
    echo "- \`RAILWAY_TOKEN\`"
    echo "- \`RAILWAY_SERVICE\` (as Variable)"
    ;;
esac
)

## Observability

| Service | Variable |
|---------|----------|
| [Sentry](https://sentry.io) | \`SENTRY_DSN\` |
| [Google Analytics](https://analytics.google.com) | \`NEXT_PUBLIC_GA_MEASUREMENT_ID\` |

Set these in your \`.env\` (and in your deployment platform's environment variables).

## Contributing

1. Create a feature branch: \`git checkout -b feat/my-feature\`
2. Make changes (use \`aider\` for AI assistance)
3. Push and open a PR → CI will run automatically
4. Merge to \`main\` → deploys automatically

## Licence

MIT
READMEEOF
ok "README.md written"
README_START
}

# ─────────────────────────────────────────────────────────────
#  Tool version checker — embedded into init.sh
# ─────────────────────────────────────────────────────────────
_append_tool_checks() {
  local out="$1"

  # Write the universal helper functions first
  cat >> "$out" <<'TOOL_CHECKS_HEADER'

# ─────────────────────────────────────────────────────────────
#  Tool version checks
# ─────────────────────────────────────────────────────────────

# Minimum versions
MIN_NODE_MAJOR=20
MIN_NPM_MAJOR=10
MIN_PNPM_MAJOR=9
MIN_BUN_MAJOR=1
MIN_PYTHON_MAJOR=3
MIN_PYTHON_MINOR=12
MIN_RUST_MAJOR=1
MIN_RUST_MINOR=77
MIN_GO_MAJOR=1
MIN_GO_MINOR=22
MIN_PHP_MAJOR=8
MIN_PHP_MINOR=2

# Load nvm if present (it's a shell function, not a binary)
_load_nvm() {
  if [[ -s "$HOME/.nvm/nvm.sh" ]]; then
    source "$HOME/.nvm/nvm.sh"
    return 0
  elif command -v brew &>/dev/null; then
    local brew_nvm
    brew_nvm="$(brew --prefix nvm 2>/dev/null)/nvm.sh"
    if [[ -s "$brew_nvm" ]]; then
      source "$brew_nvm"
      return 0
    fi
  fi
  return 1
}

# Ask user to pick/install an nvm Node version interactively
_nvm_pick_node() {
  echo ""
  warn "Node.js $MIN_NODE_MAJOR+ is required."

  if ! _load_nvm; then
    echo ""
    error "nvm not found. Install it first:"
    echo "    https://github.com/nvm-sh/nvm#installing-and-updating"
    echo ""
    echo "  Or install Node directly: https://nodejs.org"
    exit 1
  fi

  echo ""
  echo -e "  ${BOLD}Available Node versions via nvm:${NC}"
  nvm ls --no-colors 2>/dev/null | grep -E "v[0-9]+" | head -20 || true
  echo ""
  ask "Enter version to use (e.g. 22, 20, lts/iron) or press Enter to install latest LTS:"
  read -r nvm_version
  nvm_version="${nvm_version:-lts/*}"

  echo ""
  info "Running: nvm use $nvm_version (will install if missing)..."
  if ! nvm use "$nvm_version" 2>/dev/null; then
    info "Not installed — running nvm install $nvm_version ..."
    nvm install "$nvm_version"
    nvm use "$nvm_version"
  fi

  # Re-export PATH so the new node is picked up in this shell session
  export PATH="$(nvm which current | xargs dirname):$PATH"
  ok "Node $(node --version) is now active"
}

# Generic semver compare: check actual >= minimum
_version_ok() {
  local actual_major=$1
  local actual_minor=${2:-0}
  local min_major=$3
  local min_minor=${4:-0}
  (( actual_major > min_major )) && return 0
  (( actual_major == min_major && actual_minor >= min_minor )) && return 0
  return 1
}

TOOL_CHECKS_HEADER

  # ── Language-specific checks ─────────────────────────────────
  case "$CHOSEN_LANGUAGE" in
    TypeScript)
      cat >> "$out" <<'NODE_CHECK'

step "Checking Node.js..."

# Check Node
if command -v node &>/dev/null; then
  NODE_VERSION=$(node --version | sed 's/v//')
  NODE_MAJOR=$(echo "$NODE_VERSION" | cut -d. -f1)
  if _version_ok "$NODE_MAJOR" 0 "$MIN_NODE_MAJOR" 0; then
    ok "Node.js v$NODE_VERSION ✔"
  else
    warn "Node.js v$NODE_VERSION is below minimum (v${MIN_NODE_MAJOR})"
    _nvm_pick_node
  fi
else
  warn "Node.js not found"
  _nvm_pick_node
fi

# Check / select package manager
step "Checking package manager..."
PM="npm"
PMX="npx"

if command -v bun &>/dev/null; then
  BUN_VERSION=$(bun --version)
  BUN_MAJOR=$(echo "$BUN_VERSION" | cut -d. -f1)
  if _version_ok "$BUN_MAJOR" 0 "$MIN_BUN_MAJOR" 0; then
    PM="bun"; PMX="bunx"
    ok "bun v$BUN_VERSION ✔"
  else
    warn "bun v$BUN_VERSION is below minimum (v${MIN_BUN_MAJOR})"
    echo ""
    ask "Upgrade bun? [Y/n]:"
    read -r upgrade_bun
    if [[ "${upgrade_bun:-y}" =~ ^[Yy]$ ]]; then
      bun upgrade
      ok "bun upgraded to $(bun --version)"
      PM="bun"; PMX="bunx"
    else
      info "Falling back to npm"
    fi
  fi
elif command -v pnpm &>/dev/null; then
  PNPM_VERSION=$(pnpm --version)
  PNPM_MAJOR=$(echo "$PNPM_VERSION" | cut -d. -f1)
  if _version_ok "$PNPM_MAJOR" 0 "$MIN_PNPM_MAJOR" 0; then
    PM="pnpm"; PMX="pnpm dlx"
    ok "pnpm v$PNPM_VERSION ✔"
  else
    warn "pnpm v$PNPM_VERSION is below minimum (v${MIN_PNPM_MAJOR})"
    echo ""
    ask "Upgrade pnpm now? [Y/n]:"
    read -r upgrade_pnpm
    if [[ "${upgrade_pnpm:-y}" =~ ^[Yy]$ ]]; then
      npm install -g pnpm@latest
      ok "pnpm upgraded to $(pnpm --version)"
      PM="pnpm"; PMX="pnpm dlx"
    else
      info "Falling back to npm"
    fi
  fi
else
  # npm is always present with Node — just check its version
  NPM_VERSION=$(npm --version)
  NPM_MAJOR=$(echo "$NPM_VERSION" | cut -d. -f1)
  if _version_ok "$NPM_MAJOR" 0 "$MIN_NPM_MAJOR" 0; then
    ok "npm v$NPM_VERSION ✔"
  else
    warn "npm v$NPM_VERSION is below minimum (v${MIN_NPM_MAJOR})"
    echo ""
    ask "Upgrade npm now? [Y/n]:"
    read -r upgrade_npm
    if [[ "${upgrade_npm:-y}" =~ ^[Yy]$ ]]; then
      npm install -g npm@latest
      ok "npm upgraded to $(npm --version)"
    fi
  fi
fi

ok "Using package manager: $PM"
NODE_CHECK
      ;;

    Python)
      cat >> "$out" <<'PYTHON_CHECK'

step "Checking Python..."

_python_bin=""
for py in python3 python; do
  if command -v "$py" &>/dev/null; then
    _python_bin="$py"
    break
  fi
done

if [[ -z "$_python_bin" ]]; then
  error "Python not found. Install it from https://python.org or via pyenv:"
  echo "    brew install pyenv && pyenv install 3.12 && pyenv global 3.12"
  exit 1
fi

PY_VERSION=$("$_python_bin" --version 2>&1 | awk '{print $2}')
PY_MAJOR=$(echo "$PY_VERSION" | cut -d. -f1)
PY_MINOR=$(echo "$PY_VERSION" | cut -d. -f2)

if _version_ok "$PY_MAJOR" "$PY_MINOR" "$MIN_PYTHON_MAJOR" "$MIN_PYTHON_MINOR"; then
  ok "Python $PY_VERSION ✔"
else
  warn "Python $PY_VERSION is below minimum (${MIN_PYTHON_MAJOR}.${MIN_PYTHON_MINOR})"
  echo ""
  echo "  Options:"
  echo "    1) Use pyenv to install and switch version"
  echo "    2) Exit and upgrade manually"
  echo ""
  ask "Choose [1/2] (default: 1):"
  read -r py_choice
  if [[ "${py_choice:-1}" == "1" ]]; then
    if ! command -v pyenv &>/dev/null; then
      error "pyenv not found. Install it first: brew install pyenv"
      exit 1
    fi
    ask "Python version to install (e.g. 3.12.4) or Enter for latest 3.12:"
    read -r py_install_version
    py_install_version="${py_install_version:-3.12}"
    info "Running: pyenv install $py_install_version && pyenv local $py_install_version"
    pyenv install "$py_install_version" --skip-existing
    pyenv local "$py_install_version"
    export PATH="$(pyenv prefix)/bin:$PATH"
    ok "Python $(python3 --version) is now active"
  else
    error "Please upgrade Python to ${MIN_PYTHON_MAJOR}.${MIN_PYTHON_MINOR}+ and re-run."
    exit 1
  fi
fi

# Check pip
if ! command -v pip3 &>/dev/null && ! command -v pip &>/dev/null; then
  warn "pip not found — attempting to bootstrap it..."
  "$_python_bin" -m ensurepip --upgrade || {
    error "Could not bootstrap pip. Install it manually."
    exit 1
  }
fi
ok "pip available ✔"
PYTHON_CHECK
      ;;

    Rust)
      cat >> "$out" <<'RUST_CHECK'

step "Checking Rust toolchain..."

if ! command -v rustc &>/dev/null; then
  warn "Rust not found."
  echo ""
  ask "Install Rust via rustup now? [Y/n]:"
  read -r install_rust
  if [[ "${install_rust:-y}" =~ ^[Yy]$ ]]; then
    curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh -s -- -y
    source "$HOME/.cargo/env"
    ok "Rust installed: $(rustc --version)"
  else
    error "Rust is required. Install from https://rustup.rs"
    exit 1
  fi
else
  RUST_VERSION=$(rustc --version | awk '{print $2}')
  RUST_MAJOR=$(echo "$RUST_VERSION" | cut -d. -f1)
  RUST_MINOR=$(echo "$RUST_VERSION" | cut -d. -f2)
  if _version_ok "$RUST_MAJOR" "$RUST_MINOR" "$MIN_RUST_MAJOR" "$MIN_RUST_MINOR"; then
    ok "rustc $RUST_VERSION ✔"
  else
    warn "rustc $RUST_VERSION is below minimum (${MIN_RUST_MAJOR}.${MIN_RUST_MINOR})"
    echo ""
    ask "Run 'rustup update' now? [Y/n]:"
    read -r update_rust
    if [[ "${update_rust:-y}" =~ ^[Yy]$ ]]; then
      rustup update stable
      ok "Rust updated: $(rustc --version)"
    fi
  fi
fi

if ! command -v cargo &>/dev/null; then
  error "cargo not found. Re-install Rust via https://rustup.rs"
  exit 1
fi
ok "cargo $(cargo --version | awk '{print $2}') ✔"
RUST_CHECK
      ;;

    Go)
      cat >> "$out" <<'GO_CHECK'

step "Checking Go..."

if ! command -v go &>/dev/null; then
  error "Go not found. Install from https://go.dev/dl or:"
  echo "    brew install go"
  exit 1
fi

GO_VERSION=$(go version | awk '{print $3}' | sed 's/go//')
GO_MAJOR=$(echo "$GO_VERSION" | cut -d. -f1)
GO_MINOR=$(echo "$GO_VERSION" | cut -d. -f2)

if _version_ok "$GO_MAJOR" "$GO_MINOR" "$MIN_GO_MAJOR" "$MIN_GO_MINOR"; then
  ok "go $GO_VERSION ✔"
else
  warn "go $GO_VERSION is below minimum (${MIN_GO_MAJOR}.${MIN_GO_MINOR})"
  echo ""
  echo "  Download the latest Go from: https://go.dev/dl"
  echo "  Or on macOS: brew upgrade go"
  echo ""
  ask "Continue anyway? [y/N]:"
  read -r go_continue
  if [[ ! "${go_continue:-n}" =~ ^[Yy]$ ]]; then
    exit 1
  fi
fi
GO_CHECK
      ;;

    PHP)
      cat >> "$out" <<'PHP_CHECK'

step "Checking PHP & Composer..."

if ! command -v php &>/dev/null; then
  error "PHP not found. Install it:"
  echo "    brew install php"
  echo "    or via your system package manager"
  exit 1
fi

PHP_VERSION=$(php --version | head -1 | awk '{print $2}')
PHP_MAJOR=$(echo "$PHP_VERSION" | cut -d. -f1)
PHP_MINOR=$(echo "$PHP_VERSION" | cut -d. -f2)

if _version_ok "$PHP_MAJOR" "$PHP_MINOR" "$MIN_PHP_MAJOR" "$MIN_PHP_MINOR"; then
  ok "php $PHP_VERSION ✔"
else
  warn "php $PHP_VERSION is below minimum (${MIN_PHP_MAJOR}.${MIN_PHP_MINOR})"
  echo ""
  echo "  Upgrade PHP: brew upgrade php"
  echo ""
  ask "Continue anyway? [y/N]:"
  read -r php_continue
  if [[ ! "${php_continue:-n}" =~ ^[Yy]$ ]]; then
    exit 1
  fi
fi

if ! command -v composer &>/dev/null; then
  warn "Composer not found."
  echo ""
  ask "Install Composer now? [Y/n]:"
  read -r install_composer
  if [[ "${install_composer:-y}" =~ ^[Yy]$ ]]; then
    curl -sS https://getcomposer.org/installer | php
    mv composer.phar /usr/local/bin/composer
    chmod +x /usr/local/bin/composer
    ok "Composer $(composer --version | awk '{print $3}') installed"
  else
    error "Composer is required. Install from https://getcomposer.org"
    exit 1
  fi
else
  ok "Composer $(composer --version | awk '{print $3}') ✔"
fi
PHP_CHECK
      ;;
  esac
}